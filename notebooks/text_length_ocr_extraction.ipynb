{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import re\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Text From Image Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_length_from_image(image_path):\n",
    "    # Load the image using OpenCV\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply adaptive thresholding to make text stand out\n",
    "    adaptive_thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                            cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # Show the thresholded image\n",
    "    cv2.imshow('Thresholded Image', adaptive_thresh)\n",
    "    cv2.waitKey(0)  # Wait for a key press to close the window\n",
    "    cv2.destroyAllWindows()  # Close all OpenCV windows\n",
    "\n",
    "    # Convert the image back to PIL format to use with pytesseract\n",
    "    img_final = Image.fromarray(adaptive_thresh)\n",
    "\n",
    "    # OCR configuration for detecting text in multiple regions\n",
    "    ocr_config = '--oem 3 --psm 12'  # psm 12 for sparse text in a single column of variable sizes\n",
    "\n",
    "    # Extract text from the preprocessed image using pytesseract\n",
    "    extracted_text = pytesseract.image_to_string(img_final, config=ocr_config)\n",
    "    filtered_text = re.sub('[^a-zA-Z0-9]', '', extracted_text)\n",
    "    text_length = len(filtered_text)\n",
    "\n",
    "    # Return the length of the filtered text and the filtered text\n",
    "    return text_length, filtered_text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 'NSSNNNENxpSModelofigfandHoldingUREENNYERENNBB8feNNNNSNalIdeNN')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract_text_length_from_image(\"../final_figures/2017/F1_P8_Obodaru_AMJ_2017_Forgone but not Forgotten Toward a Theory of Forgone Professional Identities.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run On All images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the base directory\n",
    "base_dir = \"../final_figures\"\n",
    "\n",
    "# Initialize a list to hold all the results\n",
    "results = []\n",
    "# Iterate over each directory and subdirectory\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for file in files:\n",
    "        # Check for image files (assuming typical image extensions)\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            # Construct the full file path\n",
    "            full_path = os.path.join(root, file)\n",
    "            \n",
    "            # Extract the text length from the image\n",
    "            text_length, extracted_text = extract_text_length_from_image(full_path)\n",
    "            \n",
    "            # Extract the year from the directory name\n",
    "            year = os.path.basename(root)\n",
    "            \n",
    "            # Append the results to the list\n",
    "            results.append({\"image_name\": file, \"year\": year, \"extracted_text_length\": text_length, \"extracted_text\": extracted_text})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and save the dataframe to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>year</th>\n",
       "      <th>extracted_text_length</th>\n",
       "      <th>extracted_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>F1_P7_Orlikowski_2000_OrgSci_Using Technology ...</td>\n",
       "      <td>2000</td>\n",
       "      <td>270</td>\n",
       "      <td>Figure1EnactmentofStructuresInPracticereeereee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>F5_P13_Orlikowski_2000_OrgSci_Using Technology...</td>\n",
       "      <td>2000</td>\n",
       "      <td>265</td>\n",
       "      <td>Figure5ExampleofSkepticismTowardsTechnologyRow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>F3_P15_Feldman_2000_OrgSci_Organizational Rout...</td>\n",
       "      <td>2000</td>\n",
       "      <td>131</td>\n",
       "      <td>Figure3APerfarmativeModelofLearninginRoutinesP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>F3_P17_Kochan &amp; Rubinstein_2000_OrgSci_Toward ...</td>\n",
       "      <td>2000</td>\n",
       "      <td>967</td>\n",
       "      <td>Figure3PropositionsforaGeneralStakeholderTheor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>F1_P5_Voss et al._2000_OrgSci_Linking Organiza...</td>\n",
       "      <td>2000</td>\n",
       "      <td>343</td>\n",
       "      <td>Figure1NonprofitProfessionalTheatresRelational...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_name  year  \\\n",
       "447  F1_P7_Orlikowski_2000_OrgSci_Using Technology ...  2000   \n",
       "442  F5_P13_Orlikowski_2000_OrgSci_Using Technology...  2000   \n",
       "441  F3_P15_Feldman_2000_OrgSci_Organizational Rout...  2000   \n",
       "440  F3_P17_Kochan & Rubinstein_2000_OrgSci_Toward ...  2000   \n",
       "439  F1_P5_Voss et al._2000_OrgSci_Linking Organiza...  2000   \n",
       "\n",
       "     extracted_text_length                                     extracted_text  \n",
       "447                    270  Figure1EnactmentofStructuresInPracticereeereee...  \n",
       "442                    265  Figure5ExampleofSkepticismTowardsTechnologyRow...  \n",
       "441                    131  Figure3APerfarmativeModelofLearninginRoutinesP...  \n",
       "440                    967  Figure3PropositionsforaGeneralStakeholderTheor...  \n",
       "439                    343  Figure1NonprofitProfessionalTheatresRelational...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame from the results\n",
    "df = pd.DataFrame(results, columns=[\"image_name\", \"year\", \"extracted_text_length\", \"extracted_text\"])\n",
    "# Show the DataFrame\n",
    "df = df.sort_values('year', ascending=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as Excel file at: /Users/paulgaudin/Desktop/figure_averaging/text_extracted_from_figures.xlsx\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "\n",
    "# Get the parent directory\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "\n",
    "# Construct the full path for the Excel file\n",
    "file_path = os.path.join(parent_directory, \"text_extracted_from_figures.xlsx\")\n",
    "\n",
    "# Save the DataFrame as an Excel file\n",
    "df.to_excel(file_path, index=False)\n",
    "\n",
    "print(f\"DataFrame saved as Excel file at: {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
