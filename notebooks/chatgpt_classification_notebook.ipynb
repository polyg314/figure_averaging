{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_figures/2022/F2_P9_Kellogg_2022_OrgSci_Local Adaptation without Work Intensification.png\n",
      "conceptual diagram\n",
      "final_figures/2022/F1_P8_Kellogg_2022_OrgSci_Local Adaptation without Work Intensification.png\n",
      "cycle\n",
      "final_figures/2022/F4_P33_Sawyer & Clair_ASQ_2022_Hope Cultures in Organizations - Tackling the Grand Challenge of Commercial Sex Exploitation.png\n",
      "cycle\n",
      "final_figures/2022/F3_P30_Sawyer & Clair_ASQ_2022_Hope Cultures in Organizations - Tackling the Grand Challenge of Commercial Sex Exploitation.png\n",
      "conceptual diagram\n",
      "final_figures/2022/F1_P5_Hedberg & Lounsbury_2022_OrgSci_Not Just Small Potatoes.png\n",
      "mixed statistical plot (more than 1 statistical plot type)\n",
      "final_figures/2022/F2_P9_Waldorff & Madsen_2022_OrgStudies_Translating to Maintain Existing Practices.png\n",
      "conceptual diagram\n",
      "final_figures/2022/F3_P11_Lingo_2022_OrgStudies_Digital Curation and Creative Brokering - Managing information overload in open organizing.png\n",
      "conceptual diagram\n",
      "final_figures/2022/F2_P17_Chapple, Pollock & D'Adderio_2022_OrgStudies_From Pitching to Briefing - extending entrepreneurial storytelling to new audiences.png\n",
      "cycle\n",
      "final_figures/2022/F2_P15_Weber et al._2022_OrgStudies_Boundary Work in Response to Professionals' Contextual Constraints - Micro-strategies in Interprofessional Collaboration.png\n",
      "conceptual diagram\n",
      "final_figures/2022/F2_P17_Pamphile_2022_AMJ_Paradox Peers.png\n",
      "conceptual diagram\n",
      "final_figures/2022/F2_P20_Hui_2022_HR_Movement Oriented Labor Organizations in an Authoritatian Regime.png\n",
      "process diagram\n",
      "final_figures/2022/F1_P6_Hui_2022_HR_Movement Oriented Labor Organizations in an Authoritatian Regime.png\n",
      "conceptual diagram\n",
      "final_figures/2022/F4_P17_Cluley_2022_HR_An ethnographic study of organizational performances in business services.png\n",
      "conceptual diagram\n",
      "final_figures/2022/F4_P20_Mayo_2022_ASSQ_Syncing Up A Process Model of Emergent Interdependence in Dynamic Teams.png\n",
      "process diagram\n",
      "final_figures/2022/F2_P11_Gasparin & Neyland_2022_Organizing Tekhne.png\n",
      "photo\n",
      "final_figures/2022/F2_P8_Lingo_2022_OrgStudies_Digital Curation and Creative Brokering - Managing information overload in open organizing.png\n",
      "conceptual diagram\n",
      "final_figures/2022/F6_P15_Bouty & Gode_2022_OrgStudies_Our flight suits are not just plain blue - the co-production of coordination and bodies in military air display squadron.png\n",
      "photo\n",
      "final_figures/2022/F2_P11_Gibson_2022_AMJ_Investing in Communities Forging New Ground in Corporate Community Development through Relational and Psychological Pathways.png\n",
      "conceptual diagram\n",
      "final_figures/2022/F1_P20_Mikkelsen_2022_HR_Looking over your shoulder.png\n",
      "conceptual diagram\n",
      "final_figures/2022/F1_P9_Payne & Butler_2022_HR_Of Charities and Choice.png\n",
      "conceptual diagram\n",
      "Images classified: 20\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# new\n",
    "from openai import AsyncOpenAI\n",
    "import base64\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "  \n",
    "# Load the environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the API key\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Configuration\n",
    "openai.api_key = openai_api_key\n",
    "model_name = 'gpt-4o'  # Ensure this model version supports sessions\n",
    "\n",
    "prompt = ('You are a classifier. In the following, I am going to provide figures from different peer-reviewed papers, and I want you to classify them according to the following '\n",
    "              + 'categories each time an new image is passed: \\n\\nCategories: '+ \n",
    "              '\\\"process diagram\\\", \\\"2x2 matrix\\\", \\\"venn diagram\\\", \\\"conceptual diagram\\\", \\\"cycle\\\", \\\"hierarchical diagram\\\", \\\"bar chart\\\", ' + \n",
    "              '\\\"stacked bar chart\\\", \\\"line graph\\\", \\\"scatter plot\\\", \\\"mixed statistical plot (more than 1 statistical plot type)\\\", \\\"data structure\\\",' + \n",
    "              ' \\\"data collection, data analysis, data gathering diagrams\\\", \\\"heatmap\\\", \\\"data map\\\", \\\"organizational chart\\\", \\\"timeline\\\", \\\"drawing\\\", \\\"photo\\\"' + \n",
    "              '\\n\\nPlease choose the category that best represents and most specifically describes the image. Your response should only be an exact string matching one of the categories. '\n",
    "              )\n",
    "\n",
    "client = AsyncOpenAI()\n",
    "\n",
    "# Load the Excel file into a DataFrame\n",
    "cropped_and_labeled_df = pd.read_excel(\"../cropped_and_labeled_figs.xlsx\")\n",
    "\n",
    "count = 0\n",
    "# Loop through rows and check for 'none selected'\n",
    "for index, row in cropped_and_labeled_df.iterrows():\n",
    "    if row[\"subcategory\"] == \"none selected\":\n",
    "        base64_image = encode_image(\"../\" + row[\"new image path\"])\n",
    "        print(row[\"new image path\"])\n",
    "        image_completion = await client.chat.completions.create(model=\"gpt-4o\", messages=[{\"role\": \"user\",\"content\": [    \n",
    "            {\n",
    "                \"type\": \"text\", \n",
    "                \"text\": prompt\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                },\n",
    "                \n",
    "            }]}])\n",
    "        subcategory = image_completion.choices[0].message.content.replace('\"', '')\n",
    "        print(subcategory)\n",
    "        cropped_and_labeled_df.iloc[index, cropped_and_labeled_df.columns.get_loc('subcategory')] = subcategory\n",
    "        count = count + 1\n",
    "\n",
    "print(f'Images classified: {count}')\n",
    "cropped_and_labeled_df.to_excel(\"../cropped_and_labeled_figs.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
